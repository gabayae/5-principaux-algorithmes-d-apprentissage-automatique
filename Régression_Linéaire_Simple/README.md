## <a href="http://imsp-benin.com/" ><img src="http://imsp-benin.com/home/images/logoimsp.png" style="float:left; max-width: 80px; display: inline" alt="INSA"/> |  [*Mathématiques et Sciences Physiques*](http://imsp-benin.com/home/page.php?index=directeur&parent=presentation), [`Science des Données`](http://imsp-benin.com/home/page.php?index=deamathematique&parent=formation) 


<body><right><a href="https://fr.wikipedia.org/wiki/R%C3%A9gression_lin%C3%A9aire" ><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/0/02/Regression_lineaire_ordonnees.svg/220px-Regression_lineaire_ordonnees.svg.png" style="float:left; max-width: 80px; display: inline" alt="INSA"/></a></right></body>



La régression linéaire est l’un des algorithmes d’apprentissage supervisé les plus populaires. Il est aussi simple et parmi les mieux compris en statistique et en apprentissage automatique.

La régression linéaire est un type d’analyse prédictive de base. Le concept général de la régression est d’étudier deux questions:

  - un ensemble de variables prédictives permet-il de prédire une variable de résultat ?
  
  - quelles sont les variables les plus significatives et ont le plus d’impact sur la variable de résultat ?
  
On utilise ces estimations de régression pour expliquer les relations entre une variable dépendante et une ou plusieurs variables indépendantes. La forme la plus simple de l’équation de régression avec une variable dépendante et une variable indépendante est définie par la formule y = c + b * x, avec y = variable dépendante estimé, c = constante, b = coefficient de régression et x = variable indépendante. On parle ici de Régression linéaire simple. Pour la [regression linéaire multiple](https://github.com/gabayae/5-principaux-algorithmes-d-apprentissage-supervisE/tree/main/R%C3%A9gression_Lin%C3%A9aire_Multiple) on écrira y = c + b * x1 +…+ n*xn avec x1 jusqu’à xn les variables indépendantes et b jusqu’à n les coefficient de regression respectifs des variables.
